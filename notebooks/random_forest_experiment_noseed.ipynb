{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from verbio import readers, preprocessing, temporal, features, settings\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_LABELS = [f'P{p:03d}' for p in range(1, 74, 1)] # Participants 001-073\n",
    "TRAIN_SESSIONS = ['TEST01','TEST02','TEST03','TEST04']\n",
    "TEST_SESSIONS = ['TEST05','TEST06','TEST07','TEST08']\n",
    "DATA_DIR = '/home/jason/hubbs/project_verbio/data/raw/'\n",
    "EDA_FILENAME = 'E4_EDA_PPT.xlsx'\n",
    "HR_FILENAME = 'E4_HR_PPT.xlsx'\n",
    "ANNOTATION_FILENAME = 'MANUAL_ANNOTATION_PPT.xlsx'\n",
    "WIN_LEN = 20\n",
    "WIN_STRIDE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(participant, session):\n",
    "    eda_filepath = os.path.join(DATA_DIR, participant, session, EDA_FILENAME)\n",
    "    hr_filepath = os.path.join(DATA_DIR, participant, session, HR_FILENAME)\n",
    "    annotation_filepath = os.path.join(DATA_DIR, participant, session, ANNOTATION_FILENAME)\n",
    "    \n",
    "    if any(not os.path.exists(x) for x in (eda_filepath, hr_filepath, annotation_filepath)): return None\n",
    "    \n",
    "    eda_df = readers.read_excel(eda_filepath)\n",
    "    hr_df = readers.read_excel(hr_filepath)\n",
    "    annotation_df = readers.read_excel(annotation_filepath)\n",
    "    \n",
    "    eda_fx = get_eda_fx(eda_df)\n",
    "    hr_fx = get_hr_fx(hr_df)\n",
    "    annotation_fx = get_annotation_fx(annotation_df)\n",
    "\n",
    "    min_len = min(len(annotation_fx), len(eda_fx), len(hr_fx))\n",
    "    y = annotation_fx[:min_len]\n",
    "    eda_fx = eda_fx.iloc[:min_len]\n",
    "    hr_fx = hr_fx[:min_len]\n",
    "    \n",
    "    x_df = eda_fx\n",
    "    x_df['HR'] = hr_fx\n",
    "    \n",
    "    x = x_df.to_numpy()\n",
    "    return x, y\n",
    "    \n",
    "def get_eda_fx(eda_df):\n",
    "    # Convert EDA signals to numpy\n",
    "    eda_signal = eda_df['EDA'].to_numpy()\n",
    "    eda_times = eda_df[settings.time_key].to_numpy()\n",
    "    # Get EDA features\n",
    "    eda_fx = features.eda_features(\n",
    "        signal=eda_signal, \n",
    "        times=eda_times, \n",
    "        sr=settings.e4_eda_sr, \n",
    "        win_len=WIN_LEN, \n",
    "        win_stride=WIN_STRIDE\n",
    "    )[['SCR_Peaks', 'SCR_Amplitude']]\n",
    "    return eda_fx\n",
    "\n",
    "def get_hr_fx(hr_df):\n",
    "    # Convert HR signals to numpy\n",
    "    hr_signal = hr_df['HR'].to_numpy()\n",
    "    hr_times = hr_df[settings.time_key].to_numpy()\n",
    "    # Window HR\n",
    "    hr_fx = preprocessing.window_timed(\n",
    "        x=hr_signal,\n",
    "        times=hr_times,\n",
    "        win_len=WIN_LEN,\n",
    "        win_stride=WIN_STRIDE,\n",
    "        win_fn=lambda x: np.mean(x)\n",
    "    )\n",
    "    return np.array(hr_fx)\n",
    "\n",
    "def get_annotation_fx(annotation_df):\n",
    "    # Convert annotation signals to numpy\n",
    "    annotation_r1 = annotation_df['R1'].to_numpy()\n",
    "    annotation_r2 = annotation_df['R2'].to_numpy()\n",
    "    annotation_r4 = annotation_df['R4'].to_numpy()\n",
    "    annotation_r5 = annotation_df['R5'].to_numpy()\n",
    "    annotation_times = annotation_df[settings.time_key].to_numpy()\n",
    "    # Combine both annotators\n",
    "    annotation_mixed = np.vstack([annotation_r1, annotation_r2, annotation_r4, annotation_r5])\n",
    "    annotation_mean = np.mean(annotation_mixed, axis=0)\n",
    "    # Window annotations\n",
    "    annotation_fx = preprocessing.window_timed(\n",
    "        x=annotation_mean,\n",
    "        times=annotation_times,\n",
    "        win_len=WIN_LEN,\n",
    "        win_stride=WIN_STRIDE,\n",
    "        win_fn=lambda x: preprocessing.binarize(np.mean(x), threshold=2.5)\n",
    "    )\n",
    "    annotation_fx = np.array(annotation_fx, dtype='int')    \n",
    "    # Shift annotations back in time\n",
    "    assert WIN_LEN % WIN_STRIDE < 0.1 # Assert that they're at least somewhat divisible\n",
    "    shift_len = -int(WIN_LEN//WIN_STRIDE)\n",
    "    return temporal.shift(annotation_fx, shift_len)[:shift_len] # Shift back in time and truncate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab raw data from VerBIO dataset for training and testing sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid participant P004\n",
      "Valid participant P005\n",
      "Valid participant P008\n",
      "Valid participant P016\n",
      "Valid participant P020\n",
      "Valid participant P021\n",
      "Valid participant P023\n",
      "Valid participant P032\n",
      "Valid participant P035\n",
      "Valid participant P037\n",
      "Valid participant P039\n",
      "Valid participant P041\n",
      "Valid participant P042\n",
      "Valid participant P044\n",
      "Valid participant P047\n",
      "Valid participant P050\n",
      "Valid participant P051\n",
      "Valid participant P053\n",
      "Valid participant P060\n",
      "Valid participant P061\n",
      "Valid participant P062\n",
      "Valid participant P065\n",
      "Valid participant P066\n",
      "Valid participant P071\n",
      "Valid participant P073\n"
     ]
    }
   ],
   "source": [
    "train_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "for p in SUBJECT_LABELS:\n",
    "    valid = True\n",
    "    participant_train = []\n",
    "    participant_test = []\n",
    "\n",
    "    for s in TRAIN_SESSIONS:\n",
    "        session_data = get_data(p, s)\n",
    "        if session_data is None:\n",
    "            valid = False\n",
    "            break\n",
    "        else:\n",
    "            participant_train.append(session_data)\n",
    "    \n",
    "    for s in TEST_SESSIONS:\n",
    "        session_data = get_data(p, s)\n",
    "        if session_data is None:\n",
    "            valid = False\n",
    "            break\n",
    "        else:\n",
    "            participant_test.append(session_data)\n",
    "            \n",
    "    if valid:\n",
    "        print(f'Valid participant {p}')\n",
    "        train_dict[p] = participant_train\n",
    "        test_dict[p] = participant_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiment loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851063829787234\n",
      "Train: c0: 2356 | c1: 1595\n",
      "Test: c0: 0 | c1: 27\n",
      "(3951, 4) (3951,)\n",
      "(27, 4) (27,)\n",
      "\n",
      "0.5\n",
      "Train: c0: 2327 | c1: 1606\n",
      "Test: c0: 16 | c1: 8\n",
      "(3933, 4) (3933,)\n",
      "(24, 4) (24,)\n",
      "\n",
      "0.2666666666666667\n",
      "Train: c0: 2444 | c1: 1515\n",
      "Test: c0: 3 | c1: 26\n",
      "(3959, 4) (3959,)\n",
      "(29, 4) (29,)\n",
      "\n",
      "0.5\n",
      "Train: c0: 2338 | c1: 1631\n",
      "Test: c0: 9 | c1: 4\n",
      "(3969, 4) (3969,)\n",
      "(13, 4) (13,)\n",
      "\n",
      "0.19999999999999998\n",
      "Train: c0: 2428 | c1: 1471\n",
      "Test: c0: 3 | c1: 36\n",
      "(3899, 4) (3899,)\n",
      "(39, 4) (39,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1496: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2564102564102564\n",
      "Train: c0: 2297 | c1: 1624\n",
      "Test: c0: 30 | c1: 12\n",
      "(3921, 4) (3921,)\n",
      "(42, 4) (42,)\n",
      "\n",
      "0.5\n",
      "Train: c0: 2331 | c1: 1571\n",
      "Test: c0: 13 | c1: 6\n",
      "(3902, 4) (3902,)\n",
      "(19, 4) (19,)\n",
      "\n",
      "0.2222222222222222\n",
      "Train: c0: 2351 | c1: 1617\n",
      "Test: c0: 3 | c1: 16\n",
      "(3968, 4) (3968,)\n",
      "(19, 4) (19,)\n",
      "\n",
      "0.04081632653061225\n",
      "Train: c0: 2406 | c1: 1491\n",
      "Test: c0: 0 | c1: 48\n",
      "(3897, 4) (3897,)\n",
      "(48, 4) (48,)\n",
      "\n",
      "0.36363636363636365\n",
      "Train: c0: 2303 | c1: 1633\n",
      "Test: c0: 23 | c1: 8\n",
      "(3936, 4) (3936,)\n",
      "(31, 4) (31,)\n",
      "\n",
      "0.8260869565217392\n",
      "Train: c0: 2397 | c1: 1490\n",
      "Test: c0: 3 | c1: 52\n",
      "(3887, 4) (3887,)\n",
      "(55, 4) (55,)\n",
      "\n",
      "0.0625\n",
      "Train: c0: 2388 | c1: 1543\n",
      "Test: c0: 3 | c1: 31\n",
      "(3931, 4) (3931,)\n",
      "(34, 4) (34,)\n",
      "\n",
      "0.32\n",
      "Train: c0: 2330 | c1: 1563\n",
      "Test: c0: 3 | c1: 42\n",
      "(3893, 4) (3893,)\n",
      "(45, 4) (45,)\n",
      "\n",
      "0.35294117647058826\n",
      "Train: c0: 2437 | c1: 1499\n",
      "Test: c0: 0 | c1: 28\n",
      "(3936, 4) (3936,)\n",
      "(28, 4) (28,)\n",
      "\n",
      "0.3636363636363636\n",
      "Train: c0: 2283 | c1: 1597\n",
      "Test: c0: 18 | c1: 4\n",
      "(3880, 4) (3880,)\n",
      "(22, 4) (22,)\n",
      "\n",
      "0.36363636363636365\n",
      "Train: c0: 2385 | c1: 1605\n",
      "Test: c0: 11 | c1: 8\n",
      "(3990, 4) (3990,)\n",
      "(19, 4) (19,)\n",
      "\n",
      "Average f1:  0.3743510328449006\n"
     ]
    }
   ],
   "source": [
    "average_f = 0.0\n",
    "valid_p = 0\n",
    "for target_p in train_dict.keys():\n",
    "    aux_participants = set(train_dict.keys())\n",
    "    aux_participants.remove(target_p)\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for p in aux_participants:\n",
    "        p_data = train_dict[p]\n",
    "        p_x = [z[0] for z in p_data]\n",
    "        p_y = [z[1] for z in p_data]\n",
    "        x_train.append(np.concatenate(p_x, axis=0))\n",
    "        y_train.append(np.concatenate(p_y, axis=0))\n",
    "    x_train = np.concatenate(x_train).astype(np.float32)\n",
    "    y_train = np.concatenate(y_train).astype(int)\n",
    "    \n",
    "    p_data = test_dict[target_p]\n",
    "    x_test = np.concatenate([z[0] for z in p_data], axis=0).astype(np.float32)\n",
    "    y_test = np.concatenate([z[1] for z in p_data], axis=0).astype(int)\n",
    "    \n",
    "    train_c0 = sum(y_train == 0)\n",
    "    train_c1 = sum(y_train == 1)\n",
    "    test_c0 = sum(y_test == 0)\n",
    "    test_c1 = sum(y_test == 1)\n",
    "    \n",
    "    \n",
    "    clf = GradientBoostingClassifier(n_estimators=100, warm_start=True)\n",
    "    clf.fit(x_pretrain, y_pretrain)\n",
    "    clf.set_params(n_estimators=200)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    # Train and test model\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    if f1_score(y_pred, y_test) == 0.0:\n",
    "        continue\n",
    "    else:\n",
    "        average_f += f1_score(y_pred, y_test)\n",
    "        valid_p += 1\n",
    "        print(f1_score(y_pred, y_test))\n",
    "        print(f'Train: c0: {train_c0} | c1: {train_c1}')\n",
    "        print(f'Test: c0: {test_c0} | c1: {test_c1}')\n",
    "        print(x_train.shape, y_train.shape)\n",
    "        print(x_test.shape, y_test.shape)\n",
    "        print('')\n",
    "        \n",
    "print('Average f1: ', average_f/valid_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
