{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global libs \n",
    "import logging \n",
    "from datetime import datetime \n",
    "from collections import defaultdict\n",
    "import math\n",
    "import os\n",
    "\n",
    "# ML/DS libs\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, log_loss, precision_score, recall_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Local libs \n",
    "import reader\n",
    "import preprocessing\n",
    "import features\n",
    "import training \n",
    "import selection\n",
    "import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = [\n",
    "    'TEST01',\n",
    "    'TEST02',\n",
    "    'TEST03',\n",
    "    'TEST04',\n",
    "    'TEST05',\n",
    "    'TEST06',\n",
    "    'TEST07',\n",
    "    'TEST08'\n",
    "]\n",
    "\n",
    "participants = range(1, 74, 1) # P001 - P073\n",
    "\n",
    "raw_dir = 'data/raw_data/'\n",
    "extracted_dir = 'data/extracted_data_old/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'annotation'\n",
    "target_keys = ['R1', 'R2']\n",
    "target_key='R1'\n",
    "target_threshold = 3\n",
    "\n",
    "target_function = lambda df : features.format_annotation(\n",
    "    df,\n",
    "    window_size=20.0,\n",
    "    stride=5.0,\n",
    "    window_fn=lambda x : np.mean(x, axis=0),\n",
    "    threshold=target_threshold,\n",
    "    time_key='Time (s)',\n",
    "    target_keys=target_keys\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM feature, TO feature, Extraction Function, Format Function, Whether or not to write extraction, Use existing\n",
    "features_to_extract = [\n",
    "    [\n",
    "        'E4_EDA_PPT', \n",
    "        'excel',\n",
    "        'EDA_20sec_5sec',\n",
    "        lambda df : features.get_EDA_features(df['EDA'].to_numpy(), 4, 20.0, 5.0, df['Time (s)'].to_numpy()),\n",
    "        lambda df : features.format_extracted_features(\n",
    "            df,\n",
    "            time_key='Time (s)',\n",
    "            shift_fn=lambda df : preprocessing.shift_dataframe(df, 4, False)\n",
    "        ),\n",
    "        False,\n",
    "        False\n",
    "    ]\n",
    "]\n",
    "\n",
    "data_features = list(set([f[0] for f in features_to_extract]))\n",
    "data_formats = list(set([(f[0], f[1]) for f in features_to_extract])) # To remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data, features_missing = reader.get_pts_data(raw_dir, data_formats, participants, sessions)\n",
    "\n",
    "target_data, target_missing = reader.get_pts_data(extracted_dir, [(target_feature, 'excel')], participants, sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_search = data_features.copy()\n",
    "feature_search.append(target_feature)\n",
    "valid_pts_sessions = training.get_valid_pts_sessions(\n",
    "    participants, \n",
    "    [features_missing, target_missing],\n",
    "    sessions,\n",
    "    feature_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid sessions for Participant 1: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 4: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 5: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 8: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 13: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 16: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 20: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 21: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 23: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 27: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 32: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 35: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 37: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 38: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 39: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 41: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 42: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 43: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 44: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 45: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 46: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 47: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 48: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 49: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 50: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 51: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 53: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 58: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 60: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 61: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 62: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 65: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 66: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07']\n",
      "Valid sessions for Participant 67: ['TEST01', 'TEST02', 'TEST03', 'TEST04']\n",
      "Valid sessions for Participant 71: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n",
      "Valid sessions for Participant 73: ['TEST01', 'TEST02', 'TEST03', 'TEST04', 'TEST05', 'TEST06', 'TEST07', 'TEST08']\n"
     ]
    }
   ],
   "source": [
    "pt_dfs = training.get_pt_dfs(features_data, target_data, valid_pts_sessions, target_feature, target_function, features_to_extract, extracted_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant 5: 0.200 0.579\n",
      "Participant 8: 1.000 0.689\n",
      "Participant 16: 0.357 0.730\n",
      "Participant 20: 0.000 0.790\n",
      "Participant 21: 0.000 0.863\n",
      "Participant 23: 0.000 0.766\n",
      "Participant 32: 0.613 0.317\n",
      "Participant 41: 0.000 0.722\n",
      "Participant 42: 0.000 0.907\n",
      "Participant 51: 0.385 0.880\n",
      "Participant 53: 0.419 0.512\n",
      "Participant 60: 0.731 0.725\n",
      "Participant 62: 0.649 0.356\n",
      "Participant 71: 0.722 0.649\n",
      "Participant 73: 0.500 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jason/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for pt, session_dfs in pt_dfs.items():\n",
    "    if len(session_dfs) == 8:\n",
    "        try:\n",
    "            train_sessions = pd.concat(session_dfs[0:6]).fillna(0)\n",
    "            train_sessions = training.eq_class_dist(train_sessions, target_key, [0, 1], method='under')\n",
    "            test_sessions = pd.concat(session_dfs[6:]).fillna(0)\n",
    "            model = LogisticRegression(solver='liblinear')\n",
    "            x_train = train_sessions.drop(target_key,axis=1).to_numpy()\n",
    "            y_train = train_sessions[target_key].to_numpy()\n",
    "            x_test = test_sessions.drop(target_key, axis=1).to_numpy()\n",
    "            y_test = test_sessions[target_key].to_numpy()\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            print(f'Participant {pt}: Recall:{recall_score(y_test, y_pred):.3f} Acc:{accuracy_score(y_test, y_pred):.3f}')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
