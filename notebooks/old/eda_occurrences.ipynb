{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verbio import readers, preprocessing, temporal\n",
    "\n",
    "from scipy import stats\n",
    "import scipy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from scipy.io import wavfile \n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "from random import shuffle\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = [i for i in range(1, 74, 1)]\n",
    "\n",
    "win_size = 15.0\n",
    "stride = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "percentages = []\n",
    "for pt in pts:\n",
    "\n",
    "    base_path = f'/home/jason/hubbs/project_verbio/data/raw_data/P{pt:03d}/'\n",
    "\n",
    "    for session in ['PRE', 'POST']:\n",
    "\n",
    "        session_path = os.path.join(base_path, session)\n",
    "        eda_path = os.path.join(session_path, 'E4_EDA_PPT.xlsx')\n",
    "        hr_path = os.path.join(session_path, 'E4_HR_PPT.xlsx')\n",
    "        annotation_path = os.path.join(session_path, 'MANUAL_ANNOTATION_PPT.xlsx')\n",
    "        try:\n",
    "            annotation_df = pd.read_excel(annotation_path, engine='openpyxl')\n",
    "\n",
    "            annotations_r1 = annotation_df['R1'].to_numpy()\n",
    "            annotations_r2 = annotation_df['R2'].to_numpy()\n",
    "            \n",
    "            annotation_times = annotation_df['Time (s)'].to_numpy()\n",
    "        except IOError:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            eda_df = pd.read_excel(eda_path, engine='openpyxl')         \n",
    "\n",
    "            eda_times = eda_df['Time (s)'].to_numpy()\n",
    "            original_eda = eda_df['EDA'].to_numpy()\n",
    "            eda_signal = eda_df['EDA'].to_numpy()\n",
    "            \n",
    "            # Filter EDA with NK\n",
    "            sr = 4\n",
    "            order = 4\n",
    "            w0 = 1.5 # Cutoff frequency \n",
    "            w0 = 2 * np.array(w0) / sr \n",
    "\n",
    "            eda_signal = nk.signal_sanitize(eda_signal)\n",
    "            b, a = scipy.signal.butter(N=order, Wn=w0, btype='lowpass', analog=False, output='ba')\n",
    "            eda_signal = scipy.signal.filtfilt(b, a, eda_signal)\n",
    "            eda_signal = nk.signal_smooth(eda_signal, method='convolution', kernel='blackman', size=16)\n",
    "            \n",
    "            eda_decomp = nk.eda_phasic(eda_signal, sampling_rate=sr)\n",
    "            \n",
    "            eda_peaks, info = nk.eda_peaks(\n",
    "                eda_decomp['EDA_Phasic'].values,\n",
    "                sampling_rate=sr,\n",
    "                method='biosppy',\n",
    "                amplitude_min=0.1\n",
    "            )\n",
    "            \n",
    "            peak_indices = info['SCR_Peaks'] \n",
    "            eda_tonic = eda_decomp['EDA_Tonic']\n",
    "            \n",
    "        except IOError:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            hr_df = pd.read_excel(hr_path, engine='openpyxl')\n",
    "            \n",
    "            hr_times = hr_df['Time (s)'].to_numpy()\n",
    "            hr_data = hr_df['HR'].to_numpy()\n",
    "            \n",
    "            hr_data_grad = np.gradient(hr_data)\n",
    "        \n",
    "            grad_peaks, _ = scipy.signal.find_peaks(hr_data_grad, height=0.3)\n",
    "            \n",
    "            \n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        cluster_len = 20.0\n",
    "        cluster_stride = 5.0\n",
    "\n",
    "#         fig = plt.figure(figsize=(20,6))\n",
    "    \n",
    "#         ax1 = fig.add_subplot(211)\n",
    "#         ax1.plot(eda_times, eda_signal)\n",
    "#         ax1.grid()\n",
    "#         ax1.set_ylabel('EDA SCRs')\n",
    "        \n",
    "#         for index in peak_indices:\n",
    "#             plt.axvline(x=eda_times[index], color='red')\n",
    "            \n",
    "#         ax2 = fig.add_subplot(212)\n",
    "#         ax2.plot(hr_times, hr_data_grad)\n",
    "#         ax2.grid()\n",
    "#         ax2.set_ylabel('HR Grad')\n",
    "        \n",
    "#         for index in grad_peaks:\n",
    "#             plt.axvline(x=hr_times[index], color='red')\n",
    "#         plt.axhline(y=0, color='black')\n",
    "            \n",
    "#         plt.show()\n",
    "#         plt.clf()\n",
    "        \n",
    "        slices = temporal.time_slices(eda_times, cluster_len, cluster_stride)\n",
    "        \n",
    "        counts = []\n",
    "        timestamps = []\n",
    "        t = cluster_len\n",
    "        hop = cluster_stride\n",
    "        for t0, tk in slices:\n",
    "            window_counts = ((t0 < peak_indices) & (peak_indices < tk)).sum()\n",
    "            counts.append(window_counts)\n",
    "            timestamps.append(t)\n",
    "            t += hop\n",
    "            \n",
    "        slices = temporal.time_slices(hr_times, cluster_len, cluster_stride)\n",
    "            \n",
    "        hr_counts = []\n",
    "        hr_timestamps = []\n",
    "        t = cluster_len\n",
    "        hop = cluster_stride\n",
    "        for t0, tk in slices:\n",
    "            window_counts = ((t0 < grad_peaks) & (grad_peaks < tk)).sum()\n",
    "            hr_counts.append(window_counts)\n",
    "            hr_timestamps.append(t)\n",
    "            t += hop\n",
    "            \n",
    "\n",
    "        counts = np.array(counts)\n",
    "        counts = preprocessing.binarize(counts, 4)\n",
    "            \n",
    "        hr_counts = np.array(hr_counts)\n",
    "        hr_counts = preprocessing.binarize(hr_counts, 1)\n",
    "        \n",
    "        percentages.append(len(np.where(counts*hr_counts == 1)[0])/counts.shape[0])\n",
    "\n",
    "            \n",
    "#         fig = plt.figure(figsize=(20,6))\n",
    "#         ax1 = fig.add_subplot(211)\n",
    "#         ax1.step(timestamps, counts)\n",
    "#         ax1.grid()\n",
    "#         ax1.set_ylabel('EDA Freqs')\n",
    "#         ax2 = fig.add_subplot(212)\n",
    "#         ax2.step(hr_timestamps, hr_counts)\n",
    "#         ax2.grid()\n",
    "#         ax2.set_ylabel('HR Grad Freqs')\n",
    "#         ax2.set_xlabel('Time (s)')\n",
    "#         plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.6326530612244898, 0.0, 0.05555555555555555, 0.2608695652173913, 0.08, 0.0851063829787234, 0.13513513513513514, 0.1875, 0.05454545454545454, 0.0, 0.09090909090909091, 0.21428571428571427, 0.0, 0.2553191489361702, 0.0, 0.23636363636363636, 0.01818181818181818, 0.0196078431372549, 0.09090909090909091, 0.3508771929824561, 0.017857142857142856, 0.25, 0.0, 0.0, 0.4090909090909091, 0.0, 0.0, 0.12, 0.24528301886792453, 0.26666666666666666, 0.19642857142857142, 0.0, 0.22807017543859648, 0.019230769230769232, 0.09302325581395349, 0.1346153846153846, 0.21818181818181817, 0.07692307692307693, 0.0, 0.05357142857142857, 0.24390243902439024, 0.0, 0.17647058823529413, 0.029411764705882353, 0.38461538461538464, 0.0, 0.2222222222222222, 0.10714285714285714, 0.0625, 0.03571428571428571, 0.08928571428571429, 0.38181818181818183, 0.0, 0.0, 0.0, 0.03571428571428571, 0.0, 0.0, 0.1111111111111111, 0.05357142857142857, 0.03125, 0.35714285714285715, 0.0, 0.021739130434782608, 0.16279069767441862, 0.0, 0.34615384615384615]\n",
      "0.11196222116359389\n"
     ]
    }
   ],
   "source": [
    "print(percentages)\n",
    "print(sum(percentages)/len(percentages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
