{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import verbio as vb\n",
    "from verbio import settings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_LABELS = [f'P{p:03d}' for p in range(1, 74, 1)] # Participants 001-073\n",
    "TRAIN_SESSIONS = ['TEST01','TEST02','TEST03','TEST04']\n",
    "TEST_SESSIONS = ['TEST05','TEST06','TEST07','TEST08']\n",
    "DATA_DIR = '/home/jason/workspace/hubbs/project_verbio/data/physio/'\n",
    "EDA_FILENAME = 'E4_EDA_PPT.xlsx'\n",
    "BVP_FILENAME = 'E4_BVP_PPT.xlsx'\n",
    "ANNOTATION_FILENAME = 'MANUAL_ANNOTATION_PPT.xlsx'\n",
    "WIN_LEN = 30\n",
    "WIN_STRIDE = 15\n",
    "ANNOTATION_THRESHOLD = 2.5\n",
    "EDA_FILTER_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(participant, session):\n",
    "    eda_filepath = os.path.join(DATA_DIR, participant, session, EDA_FILENAME)\n",
    "    bvp_filepath = os.path.join(DATA_DIR, participant, session, BVP_FILENAME)\n",
    "    annotation_filepath = os.path.join(DATA_DIR, participant, session, ANNOTATION_FILENAME)\n",
    "    \n",
    "    if any(not os.path.exists(x) for x in (eda_filepath, bvp_filepath, annotation_filepath)): return None\n",
    "    \n",
    "    vbr = vb.readers.DataReader()\n",
    "    \n",
    "    eda_df = vbr.read_excel(eda_filepath)\n",
    "    bvp_df = vbr.read_excel(bvp_filepath)\n",
    "    annotation_df = vbr.read_excel(annotation_filepath)\n",
    "    \n",
    "    eda_fx = get_eda_fx(eda_df)\n",
    "    bvp_fx = get_bvp_fx(bvp_df)\n",
    "    annotation_fx = get_annotation_fx(annotation_df)\n",
    "\n",
    "    min_len = min(len(annotation_fx), len(eda_fx), len(bvp_fx))\n",
    "    annotation_fx = annotation_fx[:min_len]\n",
    "    eda_fx = eda_fx.iloc[:min_len]\n",
    "    bvp_fx = bvp_fx[:min_len]\n",
    "    \n",
    "    return pd.concat([eda_fx, bvp_fx], axis=1)\n",
    "    \n",
    "def get_eda_fx(eda_df):\n",
    "    # Convert EDA signals to numpy\n",
    "    eda_signal = eda_df['EDA'].to_numpy()\n",
    "    eda_times = eda_df[vb.settings.time_key].to_numpy()\n",
    "    \n",
    "    # Get EDA features\n",
    "    eda_fx = vb.features.eda_features(\n",
    "        signal      = eda_signal, \n",
    "        times       = eda_times, \n",
    "        sr          = vb.settings.e4_eda_sr, \n",
    "        win_len     = WIN_LEN, \n",
    "        win_stride  = WIN_STRIDE,\n",
    "        filter_size = EDA_FILTER_SIZE\n",
    "    )[['SCR_Peaks', 'SCR_Amplitude', 'SCL']]\n",
    "    \n",
    "    return eda_fx\n",
    "\n",
    "def get_bvp_fx(bvp_df):\n",
    "    # Convert BVP signals to numpy\n",
    "    bvp_signal = bvp_df['BVP'].to_numpy()\n",
    "    bvp_times = bvp_df[vb.settings.time_key].to_numpy()\n",
    "    \n",
    "    # Get BVP features\n",
    "    bvp_fx = vb.features.bvp_features(\n",
    "        signal     = bvp_signal,\n",
    "        times      = bvp_times,\n",
    "        sr         = vb.settings.e4_bvp_sr,\n",
    "        win_len    = WIN_LEN,\n",
    "        win_stride = WIN_STRIDE\n",
    "    )[['HR', 'HR_Grad']]\n",
    "    \n",
    "    return bvp_fx\n",
    "\n",
    "def get_annotation_fx(annotation_df):\n",
    "    # Convert annotation signals to numpy\n",
    "    annotation_r1 = annotation_df['R1'].to_numpy()\n",
    "    annotation_r2 = annotation_df['R2'].to_numpy()\n",
    "    annotation_r4 = annotation_df['R4'].to_numpy()\n",
    "    annotation_r5 = annotation_df['R5'].to_numpy()\n",
    "    annotation_times = annotation_df[vb.settings.time_key].to_numpy()\n",
    "    \n",
    "    # Combine both annotators\n",
    "    annotation_mixed = np.vstack([annotation_r1, annotation_r2, annotation_r4, annotation_r5])\n",
    "    annotation_mean = np.mean(annotation_mixed, axis=0)\n",
    "   \n",
    "    # Window annotations\n",
    "    annotation_fx = vb.preprocessing.window_timed(\n",
    "        x=annotation_mean,\n",
    "        times=annotation_times,\n",
    "        win_len=WIN_LEN,\n",
    "        win_stride=WIN_STRIDE,\n",
    "        win_fn=lambda x: vb.preprocessing.binarize(np.mean(x), threshold=ANNOTATION_THRESHOLD)\n",
    "    )\n",
    "    annotation_fx = np.array(annotation_fx, dtype='int') \n",
    "    \n",
    "    # Shift annotations back in time\n",
    "    assert WIN_LEN % WIN_STRIDE < 0.1 # Assert that they're at least somewhat divisible\n",
    "    shift_len = -int(WIN_LEN//WIN_STRIDE)\n",
    "    \n",
    "    return vb.temporal.shift(annotation_fx, shift_len)[:shift_len] # Shift back in time and truncate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab raw data from VerBIO dataset for training and testing sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid participant P004\n",
      "Valid participant P005\n",
      "Valid participant P008\n",
      "Valid participant P016\n",
      "Valid participant P020\n",
      "Valid participant P021\n",
      "Valid participant P023\n",
      "Valid participant P032\n",
      "Valid participant P035\n",
      "Valid participant P037\n",
      "Valid participant P039\n",
      "Valid participant P041\n",
      "Valid participant P042\n",
      "Valid participant P044\n",
      "Valid participant P047\n",
      "Valid participant P050\n",
      "Valid participant P051\n",
      "Valid participant P053\n",
      "Valid participant P060\n",
      "Valid participant P061\n",
      "Valid participant P062\n",
      "Valid participant P065\n",
      "Valid participant P071\n",
      "Valid participant P073\n"
     ]
    }
   ],
   "source": [
    "test_dict = {}\n",
    "\n",
    "for p in SUBJECT_LABELS:\n",
    "    valid = True\n",
    "    participant_test = []\n",
    "    \n",
    "    for s in TEST_SESSIONS:\n",
    "        session_data = get_data(p, s)\n",
    "        if session_data is None:\n",
    "            valid = False\n",
    "            break\n",
    "        else:\n",
    "            participant_test.append(session_data)\n",
    "            \n",
    "    if valid:\n",
    "        print(f'Valid participant {p}')\n",
    "        test_dict[p] = participant_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiment loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 54\n",
      "3 31\n",
      "6 22\n",
      "7 47\n",
      "4 20\n",
      "9 18\n",
      "19 45\n",
      "21 46\n",
      "0 53\n",
      "9 37\n",
      "12 39\n",
      "4 22\n",
      "1 36\n",
      "13 24\n",
      "11 48\n",
      "11 31\n",
      "16 45\n",
      "14 28\n",
      "2 33\n",
      "2 20\n",
      "19 38\n",
      "16 36\n",
      "15 32\n",
      "2 24\n",
      "0.2938179208699289\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.0\n",
    "n_valid = 0\n",
    "for target_p in test_dict.keys():\n",
    "    \n",
    "    p_data = pd.concat(test_dict[target_p][:3], axis=0)\n",
    "    \n",
    "    y_pred = sum((p_data['HR_Grad'].to_numpy() > 0) & (p_data['SCR_Peaks'].to_numpy() >= 9))\n",
    "    n_valid += 1\n",
    "    print(y_pred, len(p_data))\n",
    "    ratio += (y_pred/len(p_data))\n",
    "\n",
    "print(ratio/n_valid)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
